{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNQB/I3tdwwYRmYbzmx1sZi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/temahm/AiCon/blob/main/PredictSalaryOver50Kv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict income >50K. We’ll measure whether the model treats groups differently by sex and race.\n",
        "Logistic Regression vs XGBoost"
      ],
      "metadata": {
        "id": "MHHIglVqHlDT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDkpz4e1HOwP"
      },
      "outputs": [],
      "source": [
        "!pip -q install fairlearn xgboost scikit-learn pandas numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load dataset (Adult)"
      ],
      "metadata": {
        "id": "hvrTNzNjHtMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "adult = fetch_openml(\"adult\", version=2, as_frame=True)\n",
        "df = adult.frame.copy()\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "7NVLrPjFHxES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean + set target + choose sensitive attribute(s)"
      ],
      "metadata": {
        "id": "leLgcGe9HzmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df = df.replace(\"?\", np.nan).dropna()\n",
        "\n",
        "y = (df[\"class\"] == \">50K\").astype(int)\n",
        "\n",
        "A_sex  = df[\"sex\"]   # sensitive feature for fairness evaluation\n",
        "A_race = df[\"race\"]  # optional, you can do one at a time\n",
        "\n",
        "X = df.drop(columns=[\"class\"])  # keep everything for now\n",
        "X = pd.get_dummies(X, drop_first=True)"
      ],
      "metadata": {
        "id": "y3qDxtB_IE6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exclude sensitive features from training (good practice) but still keep them for evaluation."
      ],
      "metadata": {
        "id": "7tahCAc0IIUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If you want: exclude sex/race from training features\n",
        "X = X.drop(columns=[c for c in X.columns if c.startswith(\"sex_\") or c.startswith(\"race_\")])"
      ],
      "metadata": {
        "id": "QpQM-i0OIRPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train/test split"
      ],
      "metadata": {
        "id": "rb2Ug11PIZhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test, A_train, A_test = train_test_split(\n",
        "    X, y, A_sex, test_size=0.25, random_state=42, stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "FaIauwyUIck7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train two models: Logistic Regression vs XGBoost"
      ],
      "metadata": {
        "id": "kdDX8RD6Ifdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "lr = Pipeline([\n",
        "    (\"scaler\", StandardScaler(with_mean=False)),  # sparse-friendly\n",
        "    (\"model\", LogisticRegression(max_iter=2000))\n",
        "])\n",
        "\n",
        "xgb = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=4,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    eval_metric=\"logloss\",\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "lr.fit(X_train, y_train)\n",
        "xgb.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "-lyNCQrUIior"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LR is linear and easier to interpret. XGBoost is more powerful and may amplify proxy patterns."
      ],
      "metadata": {
        "id": "nKjFH_WrIlCT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Measure accuracy + fairness metrics (group gaps)**\n",
        "\n",
        "Use fairlearn MetricFrame to compute metrics by group."
      ],
      "metadata": {
        "id": "A4bYPgWxIpMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from fairlearn.metrics import MetricFrame, selection_rate, false_positive_rate, false_negative_rate\n",
        "\n",
        "def evaluate(model, X_test, y_test, A_test, name=\"model\"):\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    mf = MetricFrame(\n",
        "        metrics={\n",
        "            \"accuracy\": accuracy_score,\n",
        "            \"selection_rate\": selection_rate,     # P(ŷ=1)\n",
        "            \"FPR\": false_positive_rate,\n",
        "            \"FNR\": false_negative_rate,\n",
        "        },\n",
        "        y_true=y_test,\n",
        "        y_pred=y_pred,\n",
        "        sensitive_features=A_test\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=== {name} (overall) ===\")\n",
        "    print(mf.overall)\n",
        "\n",
        "    print(f\"\\n=== {name} (by group) ===\")\n",
        "    print(mf.by_group)\n",
        "\n",
        "    print(f\"\\n=== {name} (group gaps: max - min) ===\")\n",
        "    print(mf.difference())\n",
        "\n",
        "evaluate(lr,  X_test, y_test, A_test, \"Logistic Regression\")\n",
        "evaluate(xgb, X_test, y_test, A_test, \"XGBoost\")"
      ],
      "metadata": {
        "id": "rfGUhxVUI2gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Selection rate**: who gets predicted “>50K”\n",
        "\n",
        "**FPR**: among true ≤50K, how often we incorrectly predict >50K\n",
        "\n",
        "**FNR**: among true >50K, how often we incorrectly predict ≤50K\n",
        "\n",
        "**Group gap**: max(metric) − min(metric) across groups (basic disparity measure)"
      ],
      "metadata": {
        "id": "u_wjKo6xI6Xa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overall Performance\n",
        "\n",
        "**Logistic Regression (overall)**\n",
        "\n",
        "Accuracy: 0.846\n",
        "\n",
        "FPR: 0.0686\n",
        "\n",
        "FNR: 0.413\n",
        "\n",
        "\n",
        "**XGBoost (overall)**\n",
        "\n",
        "Accuracy: 0.866\n",
        "\n",
        "FPR: 0.0581\n",
        "\n",
        "FNR: 0.365\n",
        "\n",
        "XGBoost performs better. It increases accuracy from 84.6% to 86.6%.\n",
        "It reduces false positives and reduces false negatives overall.\n",
        "\n",
        "If we stopped here, we would conclude XGBoost is better.\n",
        "\n",
        "\n",
        "# Group-Level Results (This Is Where Bias Appears)\n",
        "\n",
        "## Measuring fairness across sex.\n",
        "\n",
        "### Selection Rate (Who Gets Predicted >50K)\n",
        "\n",
        "**Logistic Regression**:\n",
        "\n",
        "Female: 8.1%\n",
        "\n",
        "Male: 25.3%\n",
        "\n",
        "Gap: 17.2 percentage points\n",
        "\n",
        "\n",
        "**XGBoost**:\n",
        "\n",
        "Female: 8.3%\n",
        "\n",
        "Male: 25.8%\n",
        "\n",
        "Gap: 17.5 percentage points\n",
        "\n",
        "Men are predicted to earn >50K about 3x more often than women.\n",
        "\n",
        "Even though the model does not use sex directly, disparities persist.\n",
        "\n",
        "### Learning:\n",
        "\n",
        "*“Removing sensitive features does not remove bias.”*"
      ],
      "metadata": {
        "id": "9nXW2tz9ahSh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Error Disparities (The Evidence)\n",
        "\n",
        "##FNR (False Negative Rate).\n",
        "\n",
        "FNR matters because:\n",
        "\n",
        "*It measures how often we deny opportunity to someone who actually qualifies.*\n",
        "\n",
        "Logistic Regression FNR:\n",
        "\n",
        "Female: 50.1%\n",
        "\n",
        "Male: 39.6%\n",
        "\n",
        "Gap: 10.5 points\n",
        "\n",
        "\n",
        "**XGBoost FNR**:\n",
        "\n",
        "Female: 46.6%\n",
        "\n",
        "Male: 34.5%\n",
        "\n",
        "Gap: 12.0 points\n",
        "\n",
        "This is key.\n",
        "\n",
        "Among people who truly earn >50K, women are more likely to be incorrectly classified as ≤50K.\n",
        "\n",
        "And even more powerful:\n",
        "\n",
        "XGBoost reduces FNR overall — but increases the disparity.\n",
        "This is the core teaching insight.\n",
        "\n",
        "#Tradeoff\n",
        "\n",
        "| Metric        | Logistic | XGBoost |\n",
        "| ------------- | -------- | ------- |\n",
        "| Accuracy      | 84.6%    | 86.6%   |\n",
        "| FNR Gap       | 10.5%    | 12.0%   |\n",
        "| Selection Gap | 17.2%    | 17.5%   |\n",
        "\n",
        "----------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "XGBoost is more powerful. It captures nonlinear patterns and proxy relationships.\n",
        "\n",
        "Some of those patterns reflect historical inequality in the data.\n",
        "\n",
        "## So the model becomes more accurate — but also better at reproducing structural inequity.\n",
        "----------------------------------------\n",
        "\n",
        "# Fairness is not a property of the algorithm — it is a property of the entire socio-technical system.\n",
        "\n",
        "Then transition to:\n",
        "\n",
        "- Human-in-the-loop\n",
        "\n",
        "- Governance oversight\n",
        "\n",
        "- Threshold adjustments\n",
        "\n",
        "- Fairness constraints\n",
        "\n"
      ],
      "metadata": {
        "id": "R29NMnKwcuH_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        "."
      ],
      "metadata": {
        "id": "uIACdsucXPgG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **A simple mitigation (Human-in-the-loop + review queue)**\n",
        "\n",
        "\n",
        "**Idea**: Send uncertain cases to a human reviewer."
      ],
      "metadata": {
        "id": "tw-CO3zWJLDn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step A: get probabilities**"
      ],
      "metadata": {
        "id": "hiu1z_ROJl_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "proba = xgb.predict_proba(X_test)[:, 1]  # probability of >50K"
      ],
      "metadata": {
        "id": "So7sHUsAJrqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step B: define an “uncertain band” and review it**"
      ],
      "metadata": {
        "id": "_G6xtXlAJy55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "low, high = 0.45, 0.55\n",
        "needs_review = (proba >= low) & (proba <= high)\n",
        "\n",
        "auto_pred = (proba > 0.5).astype(int)\n",
        "\n",
        "print(\"Review rate:\", needs_review.mean())"
      ],
      "metadata": {
        "id": "aELsseynJ2v9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step C: simulate “human correction”**\n",
        "\n",
        "simulate that humans correct reviewed items using the ground truth (for this demo, this represents expert review)."
      ],
      "metadata": {
        "id": "cgExeHs2J5NQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_pred = auto_pred.copy()\n",
        "final_pred[needs_review] = y_test.iloc[needs_review].values  # simulated human correction"
      ],
      "metadata": {
        "id": "x4rPItIKJ9E8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step D: re-evaluate fairness after HITL**"
      ],
      "metadata": {
        "id": "j-YjgjBrKL1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fairlearn.metrics import MetricFrame, selection_rate, false_positive_rate, false_negative_rate\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "mf = MetricFrame(\n",
        "    metrics={\n",
        "        \"accuracy\": accuracy_score,\n",
        "        \"selection_rate\": selection_rate,\n",
        "        \"FPR\": false_positive_rate,\n",
        "        \"FNR\": false_negative_rate,\n",
        "    },\n",
        "    y_true=y_test,\n",
        "    y_pred=final_pred,\n",
        "    sensitive_features=A_test\n",
        ")\n",
        "\n",
        "print(\"\\n=== XGBoost + Human Review (overall) ===\")\n",
        "print(mf.overall)\n",
        "\n",
        "print(\"\\n=== XGBoost + Human Review (by group) ===\")\n",
        "print(mf.by_group)\n",
        "\n",
        "print(\"\\n=== XGBoost + Human Review (group gaps) ===\")\n",
        "print(mf.difference())"
      ],
      "metadata": {
        "id": "6_Y_daMrKPRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HITL Results Analysis\n",
        "\n",
        "###Overall Performance Improved\n",
        "\n",
        "**XGBoost (before HITL)**\n",
        "\n",
        "Accuracy: 0.8659\n",
        "\n",
        "FPR: 0.0581\n",
        "\n",
        "FNR: 0.3647\n",
        "\n",
        "**XGBoost + Human Review**\n",
        "\n",
        "Accuracy: 0.8866 ⬆\n",
        "\n",
        "FPR: 0.0470 ⬇\n",
        "\n",
        "FNR: 0.3148 ⬇\n",
        "\n",
        "By sending uncertain cases to human review, we improved accuracy from 86.6% to 88.7%.\n",
        "\n",
        "**False negatives decreased substantially**\n",
        "\n",
        "#Look at Group-Level Fairness\n",
        "\n",
        "###Selection Rate Gap\n",
        "\n",
        "Before HITL (XGBoost): Gap: 0.1749\n",
        "\n",
        "After HITL: Gap: 0.1754\n",
        "\n",
        "**Selection disparity is roughly unchanged. HITL does not automatically fix structural imbalance.**\n",
        "\n",
        "--------\n",
        "\n",
        "**FPR Gap (False Positive Gap)**\n",
        "\n",
        "Before HITL: Gap: 0.0617\n",
        "\n",
        "After HITL: Gap: 0.0493\n",
        "\n",
        "The difference in false positive errors between men and women decreased.\n",
        "\n",
        "------------\n",
        "**FNR Gap (Most Important)**\n",
        "\n",
        "Before HITL: Gap: 0.1205\n",
        "\n",
        "After HITL: Gap: 0.1143\n",
        "\n",
        "Slight reduction.\n",
        "\n",
        "But what matters more:\n",
        "\n",
        "**Female FNR went from: 0.4658 → 0.4106**\n",
        "\n",
        "Male FNR went from:0.3453 → 0.2963\n",
        "\n",
        "**Both improved**\n"
      ],
      "metadata": {
        "id": "za49Ucyvaw9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##The algorithm alone improved predictive performance but preserved disparity\n",
        "\n",
        "\n",
        "##When we added a human review band for uncertain cases, overall error decreased and some disparities shrank\n",
        "\n",
        "#This demonstrates that fairness is not purely a modeling problem — it is a governance design problem"
      ],
      "metadata": {
        "id": "MBzT9Zi3ePXm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We’re not claiming humans are perfect.\n",
        "\n",
        "We’re showing a governance pattern: automation where confident; human oversight where uncertain.\n",
        "\n",
        "This is practical in admissions, scholarships, internships, hiring shortlists, etc."
      ],
      "metadata": {
        "id": "frFWF9kSKRys"
      }
    }
  ]
}